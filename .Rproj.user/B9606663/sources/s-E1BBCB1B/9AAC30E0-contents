

# #Read in shapefiles
shp2_v2.8<-rgdal::readOGR("Y:/Arran/PhD/Shapefiles/YF_americas_adm2.shp", stringsAsFactors = FALSE)
shp1_v2.8<-rgdal::readOGR("Y:/Arran/PhD/Shapefiles/YF_americas_adm1.shp", stringsAsFactors = FALSE)
shp0<-rgdal::readOGR("Y:/Arran/PhD/Shapefiles/YF_americas_adm0.shp", stringsAsFactors = FALSE)

#YF endemic countries
shp2_endemic<-shp2_v2.8[shp2_v2.8$ISO %in% c("ARG", "BOL", "BRA", "COL", "ECU", "GUF", "GUY", "PAN", "PER", "PRY", "SUR", "VEN"), ]
shp1_endemic<-shp1_v2.8[shp1_v2.8$ISO %in% c("ARG", "BOL", "BRA", "COL", "ECU", "GUF", "GUY", "PAN", "PER", "PRY", "SUR", "VEN"), ]

# library(rgeos)
# 
# 
# reduce_size_shp2_endemic<-gSimplify(shp2_endemic, tol = 1, topologyPreserve = T)
# red_shp2_end_df<-SpatialPolygonsDataFrame(reduce_size_shp2_endemic, data = as.data.frame(shp2_endemic), match.ID = F)
# object.size(shp2_endemic)/1024^2
# object.size(red_shp2_end_df)/1024^2
# 
# reduce_size_shp1_endemic<-gSimplify(shp1_endemic, tol = 1, topologyPreserve = T)
# red_shp1_end_df<-SpatialPolygonsDataFrame(reduce_size_shp1_endemic, data = as.data.frame(shp1_endemic), match.ID = F)
# object.size(shp1_endemic)/1024^2
# object.size(red_shp1_end_df)/1024^2
# 
# library(rgdal)
# writeOGR(obj=red_shp2_end_df, dsn="tempdir", layer="end_YF_shp2", driver="ESRI Shapefile")
# writeOGR(obj=red_shp1_end_df, dsn="tempdir", layer="end_YF_shp1", driver="ESRI Shapefile")
# 



#Set up list with all the same (legacy reasons)
shplist<-list("shp2_v1.0"=shp2_v2.8, "shp2_v2.0"=shp2_v2.8, "shp2_v2.8"=shp2_v2.8)

#Read in campaign data
schedule_unclean<-read.csv("Y:/Arran/PhD/Literature/Latin America/Vaccination/latin_america_vaccination_vacidfix.csv", header=T, stringsAsFactors=F, na.strings="NA")

#Read in EPI data
epi<-read.csv("Y:/Arran/PhD/Literature/Latin America/Vaccination/epi_LA_admin.csv", header=T, stringsAsFactors=F, na.strings="NA")

#Country isos
countryiso<-unique(c(unique(schedule_unclean$country.code), epi$ISO_code, "GUF"))
if(any(countryiso == "TTO")) countryiso<-countryiso[-which(countryiso %in% c("TTO"))]

#Clean schedules
schedule_unclean<-if(any(schedule_unclean$country.code == "TTO")) schedule_unclean[-which(schedule_unclean$country.code == "TTO"), ] else schedule_unclean
# schedule_unclean<-schedule_unclean[-which(schedule_unclean$country.code == "BRA" & schedule_unclean$year %in% 1994:2016), ]

BRA_data<-read.csv("Y:/Arran/PhD/Brazil_PAHO/Brazil_PAHO_meeting_work/data/vaccination_data/vacc_doses_translated_gadm2.8_220219_update.csv", stringsAsFactors = FALSE)
BRA_data<-BRA_data[-which(BRA_data$doses == 0), ]
BRA_data<-BRA_data[-which(BRA_data$year == "missing"), ]
BRA_data$skew<-1

schedule_unclean<-schedule_unclean[-which(schedule_unclean$country.code == "BRA" & schedule_unclean$year %in% 1994:2016), ]
schedule<-csv_formater(rbind(schedule_unclean, BRA_data))

#Load populations
pop_csv<-as.data.frame(fread("Y:/Arran/PhD/Literature/Latin America/latin_countries_population.csv", header=T, stringsAsFactors=F, na.strings="NA"))


load("Y:/Arran/PhD/arran_packages/popvac_package/data/inbuilt_data/poptab.RData")
load("Y:/Arran/PhD/arran_packages/popvac_package/data/inbuilt_data/global_annual_age.RData")
load("Y:/Arran/PhD/arran_packages/popvac_package/data/inbuilt_data/gadm1_adm1.RData")


# # extra_ISO<-unique(shp2_v2.8$ISO)
# # these_ISO<-extra_ISO[-which(extra_ISO %in% unique(pop_csv$ISO))]
# # 
# # lots_extra<-sapply(these_ISO, function(x){
# #   csv_to_adm2pop(x)
# # }, simplify = FALSE)
# # 
# # all_dflist<-sapply(1:ncol(lots_extra), function(x){
# #   this<-lots_extra[, x]
# #   
# #   blank_df<-data.frame(matrix(rep(NA, length(this[[1]])*length(this)), ncol = length(this)))
# #   colnames(blank_df)<-names(this)
# #   for(i in 1:length(this)){
# #     blank_df[, i]<-unlist(this[[i]])
# #   }
# #   blank_df
# #   
# # }, simplify = FALSE)
# # 
# # all_together<-do.call(rbind, all_dflist)
# # all_together2<-all_together[all_together$Date %in% 2000:2017, ]
# # 
# pop_csv2<-rbind(pop_csv, all_together2)
# # 
# smaller_tab<-pop_csv2[pop_csv2$Date %in% 2000:2017, ]
# smaller_tab2<-cbind(smaller_tab[, c(3, 4, 6)], rowSums(smaller_tab[, 9:ncol(smaller_tab)]))
# smaller_tab2$SPID<-paste0(smaller_tab2$ISO, smaller_tab2$adm1_id)
# 
# these_guys<-sapply(2000:2017, function(j){
#   this_one<-smaller_tab2[smaller_tab2$Date == j, ]
#   tiny_df<-aggregate(this_one[, 4], by = list(this_one$SPID), FUN = sum)
#   tiny_df$date<-j
#   tiny_df
# }, simplify = FALSE)
# 
# all_files<-do.call(rbind, these_guys)
# 
# 
# 
# 
# names(all_files)<-c("SPID", "pop", "year")
# # 
# # 
# # 
# write.csv(all_files, "Literature/Latin America/simple_adm1_latin_countries_population.csv", row.names = FALSE)
